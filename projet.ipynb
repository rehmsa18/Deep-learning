{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "847GP8BjW6Ec"
      },
      "source": [
        "#**Install**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXReID_EW9kv",
        "outputId": "c16fb15f-2c06-439f-a82f-8bcea0d9f323"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.62.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy) (3.10.0.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n"
          ]
        }
      ],
      "source": [
        "pip install spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j03M1_GfYuQa",
        "outputId": "0c7a83ae-89ff-42b7-feac-6fe8b55d2b34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting fr_core_news_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-2.2.5/fr_core_news_sm-2.2.5.tar.gz (14.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.7 MB 9.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from fr_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (4.62.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.0.6)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.0.6)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.6)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_sm==2.2.5) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.10.0.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.24.3)\n",
            "Building wheels for collected packages: fr-core-news-sm\n",
            "  Building wheel for fr-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fr-core-news-sm: filename=fr_core_news_sm-2.2.5-py3-none-any.whl size=14727026 sha256=725ddf2c92c8e812a3ddcaf1d681d2a9c0664549c3a599e496cdc9be1a1000fd\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-8fitpd49/wheels/c9/a6/ea/0778337c34660027ee67ef3a91fb9d3600b76777a912ea1c24\n",
            "Successfully built fr-core-news-sm\n",
            "Installing collected packages: fr-core-news-sm\n",
            "Successfully installed fr-core-news-sm-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('fr_core_news_sm')\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download fr_core_news_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDUNQsURI7q4"
      },
      "outputs": [],
      "source": [
        "!pip install -q tensorflow_datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6UbcRqtW9wi"
      },
      "source": [
        "#**Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Pk54fxGXz9O"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "from sklearn import preprocessing\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import f1_score, accuracy_score \n",
        "import collections\n",
        "import nltk\n",
        "import tensorflow_datasets as tfds\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow import keras\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM,Dense, Embedding, LayerNormalization\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOHcd0rdYNGf"
      },
      "source": [
        "# **Load Data and Preprocessing** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oCk5jrTZYKuZ"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv(\"train.csv\")\n",
        "df_test = pd.read_csv(\"test.csv\")\n",
        "df_val = pd.read_csv(\"val.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wP_e67adgKpF"
      },
      "outputs": [],
      "source": [
        "def clean_text( string: str, punctuations=r'''!()[]{};:'\"\\,<>./?@#%^&*_''') -> str:\n",
        "  #on enleve les chiffres\n",
        "    string=re.sub(r'[0-9]+','',string)\n",
        "  #on enleve la ponctuation\n",
        "    for x in string.lower():\n",
        "      if x in punctuations:\n",
        "        string=string.replace(x,\" \")\n",
        "  #on met en miniscule\n",
        "    string=string.lower()\n",
        "    return string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XGKaEM7kgi6J"
      },
      "outputs": [],
      "source": [
        "df_list=[clean_text(x) for x in df_train['RawText'].astype(str)]\n",
        "df_train = pd.DataFrame(list(zip(df_list, list(df_train['ICD10']))), columns =['RawText', 'ICD10'])\n",
        "\n",
        "df_list=[clean_text(x) for x in df_test['RawText'].astype(str)]\n",
        "df_test = pd.DataFrame(list(zip(df_list, list(df_test['ICD10']))), columns =['RawText', 'ICD10'])\n",
        "\n",
        "df_list=[clean_text(x) for x in df_val['RawText'].astype(str)]\n",
        "df_val = pd.DataFrame(list(zip(df_list, list(df_val['ICD10']))), columns =['RawText', 'ICD10'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H7iT25y6gcEA"
      },
      "outputs": [],
      "source": [
        "df_labels=pd.concat([df_train['ICD10'], df_test['ICD10'],df_val['ICD10']])\n",
        "labels=preprocessing.LabelEncoder().fit_transform(df_labels)\n",
        "\n",
        "y_train = labels[:181763]\n",
        "y_test = labels[181763:211763]\n",
        "y_val = labels[211763:241763]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dM-VlZi8XD4T"
      },
      "source": [
        "# **Exercice 1 :** Description du jeu de données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kosVtQvUbT9Z"
      },
      "outputs": [],
      "source": [
        "df = pd.concat([df_train, df_test, df_val], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "cCQx3Vk4bbkA",
        "outputId": "90af2425-93b7-47ac-bb72-e98e5bd0f14c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RawText</th>\n",
              "      <th>ICD10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>thrombose veineuse profonde cuisse gauche</td>\n",
              "      <td>I802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>hémiplégie post-traumatique</td>\n",
              "      <td>S099</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     RawText ICD10\n",
              "0  thrombose veineuse profonde cuisse gauche  I802\n",
              "1                hémiplégie post-traumatique  S099"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58gSH1VpcBTn",
        "outputId": "6dcca7de-944e-4662-8902-1799d3b47362"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "S062    1472\n",
              "C798    1343\n",
              "C859    1067\n",
              "C349     998\n",
              "Z924     850\n",
              "        ... \n",
              "K65        1\n",
              "Y462       1\n",
              "F650       1\n",
              "T529       1\n",
              "T366       1\n",
              "Name: ICD10, Length: 9541, dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['ICD10'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yohK9Whhetp4",
        "outputId": "51b037a1-6c2a-4ce3-b270-a40617e0afe2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Il existe: 32653 mots différents dans nos données textuelles.\n"
          ]
        }
      ],
      "source": [
        "uniqueWords = list(set(\" \".join(df['RawText']).lower().split(\" \")))\n",
        "nbWords = len(uniqueWords)\n",
        "print(\"Il existe: \"+str(nbWords)+\" mots différents dans nos données textuelles.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G92bgQp9fmid",
        "outputId": "444323e1-b884-41cd-ba53-9981d23a79f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Il existe: 9541 CIM différents dans le jeu de données.\n"
          ]
        }
      ],
      "source": [
        "nbClass=len(df.ICD10.unique())\n",
        "print(\"Il existe: \"+str(nbClass)+\" CIM différents dans le jeu de données.\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "zxMELcNUgXGH",
        "outputId": "a883fb50-5c7c-41ce-bd49-8c2a0552d780"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1800x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "dicClass=collections.Counter(df[\"ICD10\"])\n",
        "\n",
        "plt.figure(figsize=(25, 10))\n",
        "plt.bar(list(dicClass.keys())[:50],list(dicClass.values())[:50], color=\"maroon\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otDxudlTiT0G"
      },
      "source": [
        "Le jeu de données n'est pas équilibré, ainsi, la métrique à utiliser est la f1 score et non l'accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tW1HKWFsW9y-"
      },
      "source": [
        "# **Exercice 2** : Classification du premier caractère du code CIM-10 à partir du langage naturel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vYyK3rmVve6"
      },
      "outputs": [],
      "source": [
        "df_train['ICD10_1_Carac']=df_train['ICD10'].apply(lambda x: x[0])\n",
        "df_test['ICD10_1_Carac']=df_test['ICD10'].apply(lambda x: x[0])\n",
        "df_val['ICD10_1_Carac']=df_val['ICD10'].apply(lambda x: x[0])\n",
        "\n",
        "df_train['ICD10_1_Carac']=preprocessing.LabelEncoder().fit_transform(df_train.ICD10_1_Carac.values)\n",
        "df_test['ICD10_1_Carac']=preprocessing.LabelEncoder().fit_transform(df_test.ICD10_1_Carac.values)\n",
        "df_val['ICD10_1_Carac']=preprocessing.LabelEncoder().fit_transform(df_val.ICD10_1_Carac.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8PPmJMZi_sa",
        "outputId": "4cbb5421-8c15-4da0-a872-0d2fbbebda29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nombre de mots dans notre vocabulaire (après nettoyage: suppression de la ponctuation et mise en miniscule):  28970\n",
            "Nombre de classes :  26\n",
            "Taille des vecteurs qui contienderont les documents :  32 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "uniqueWords = list(set(\" \".join(df_train['RawText']).lower().split(\" \")))\n",
        "max_features = len(uniqueWords)\n",
        "print(\"Nombre de mots dans notre vocabulaire (après nettoyage: suppression de la ponctuation et mise en miniscule): \", max_features)\n",
        "\n",
        "nbre_classes = len(set(df_train['ICD10_1_Carac']))\n",
        "print(\"Nombre de classes : \", nbre_classes)\n",
        "\n",
        "# La taille du vecteur document (première couche) doit être égale à la taille du document avec le plus grand nombre de mots\n",
        "max_len = df_train.RawText.str.split(\" \").str.len().max()\n",
        "print(\"Taille des vecteurs qui contienderont les documents : \", max_len, \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqdRAKUJi0aw",
        "outputId": "96564970-f8dd-4a9d-bda6-ad8ddb8d450c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----- Entrainement du modèle -----\n",
            "Epoch 1/5\n",
            "5681/5681 [==============================] - 119s 20ms/step - loss: 1.2610 - accuracy: 0.6547 - val_loss: 0.7445 - val_accuracy: 0.7896\n",
            "Epoch 2/5\n",
            "5681/5681 [==============================] - 141s 25ms/step - loss: 0.5979 - accuracy: 0.8282 - val_loss: 0.6203 - val_accuracy: 0.8147\n",
            "Epoch 3/5\n",
            "5681/5681 [==============================] - 108s 19ms/step - loss: 0.4582 - accuracy: 0.8588 - val_loss: 0.5880 - val_accuracy: 0.8237\n",
            "Epoch 4/5\n",
            "5681/5681 [==============================] - 117s 21ms/step - loss: 0.3936 - accuracy: 0.8722 - val_loss: 0.5714 - val_accuracy: 0.8277\n",
            "Epoch 5/5\n",
            "5681/5681 [==============================] - 86s 15ms/step - loss: 0.3567 - accuracy: 0.8805 - val_loss: 0.5704 - val_accuracy: 0.8284\n",
            "\n",
            "----- Evaluation du modele  -----\n",
            "938/938 [==============================] - 6s 6ms/step - loss: 0.5661 - accuracy: 0.8333\n",
            "Accuracy: 0.8332666754722595\n",
            "\n",
            "----- Evaluation du modele : f1-Score  -----\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.8319900155222053"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vectorize_layer = tf.keras.layers.TextVectorization(max_tokens=28970, output_mode='int')\n",
        "\n",
        "vectorize_layer.adapt(df_train[\"RawText\"])\n",
        "\n",
        "#Construction de notre réseau de neuronne \n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "model.add(tf.keras.Input(shape=(1,), dtype=tf.string))\n",
        "model.add(vectorize_layer)\n",
        "model.add(tf.keras.layers.Embedding(28970, output_dim=32, mask_zero=True))\n",
        "model.add(tf.keras.layers.LSTM(32, dropout=0.1))\n",
        "model.add( tf.keras.layers.Dense(26,activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(\"----- Entrainement du modèle -----\")\n",
        "model.fit(x=df_train[\"RawText\"],y= df_train['ICD10_1_Carac'], epochs=5, validation_data=(df_val['RawText'], df_val['ICD10_1_Carac']))\n",
        "\n",
        "print(\"\\n----- Evaluation du modele  -----\")\n",
        "print(\"Accuracy:\", model.evaluate(df_test['RawText'],df_test['ICD10_1_Carac'])[1])\n",
        "\n",
        "yhat_probs = model.predict(df_test['RawText'], verbose=0)\n",
        "y_pred = np.argmax(yhat_probs,axis=1)\n",
        "\n",
        "print(\"\\n----- Evaluation du modele : f1-Score  -----\")\n",
        "f1_score(df_test['ICD10_1_Carac'].to_numpy(), y_pred, average='weighted')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1OsK4jVeNzl"
      },
      "source": [
        "# **Exercice 3 :** Classification du code CIM-10 entier à partir du langage naturel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBgvzz8MeWPF"
      },
      "source": [
        "### Partie 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jg-UH3kKeNzm",
        "outputId": "e360a2f5-9a1b-47d8-ec4b-b745ca4b489c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nombre de mots dans notre vocabulaire (après nettoyage) :  28970\n",
            "Nombre de classes dans le train :  9248\n",
            "Taille des vecteurs qui contienderont les documents :  32 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "uniqueWords = list(set(\" \".join(df_train['RawText']).lower().split(\" \")))\n",
        "max_features = len(uniqueWords)\n",
        "print(\"Nombre de mots dans notre vocabulaire (après nettoyage) : \", max_features)\n",
        "\n",
        "nbre_classes = len(set(df_train['ICD10']))\n",
        "print(\"Nombre de classes: \", nbre_classes)\n",
        "\n",
        "# La taille du vecteur document (première couche) doit être égale à la taille du document avec le plus grand nombre de mots\n",
        "max_len = df_train.RawText.str.split(\" \").str.len().max()\n",
        "print(\"Taille des vecteurs qui contienderont les documents : \", max_len, \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVGUuCBWeNzn",
        "outputId": "78b5a395-ccae-46a3-8cb0-a7548b969a86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----- Entrainement du modèle -----\n",
            "Epoch 1/8\n",
            "5681/5681 [==============================] - 302s 52ms/step - loss: 6.8007 - accuracy: 0.0775\n",
            "Epoch 2/8\n",
            "5681/5681 [==============================] - 314s 55ms/step - loss: 4.1361 - accuracy: 0.2973\n",
            "Epoch 3/8\n",
            "5681/5681 [==============================] - 357s 63ms/step - loss: 2.7710 - accuracy: 0.4677\n",
            "Epoch 4/8\n",
            "5681/5681 [==============================] - 297s 52ms/step - loss: 2.0131 - accuracy: 0.5794\n",
            "Epoch 5/8\n",
            "5681/5681 [==============================] - 299s 53ms/step - loss: 1.5472 - accuracy: 0.6586\n",
            "Epoch 6/8\n",
            "5681/5681 [==============================] - 283s 50ms/step - loss: 1.2434 - accuracy: 0.7112\n",
            "Epoch 7/8\n",
            "5681/5681 [==============================] - 291s 51ms/step - loss: 1.0325 - accuracy: 0.7495\n",
            "Epoch 8/8\n",
            "5681/5681 [==============================] - 292s 51ms/step - loss: 0.8854 - accuracy: 0.7758\n",
            "\n",
            "----- Evaluation du modele : f1-Score  -----\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.5848366311436312"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vectorize_layer = tf.keras.layers.TextVectorization(max_tokens=36326, output_mode='int')\n",
        "\n",
        "vectorize_layer.adapt(df_train[\"RawText\"])\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.Input(shape=(1,), dtype=tf.string))\n",
        "model.add(vectorize_layer)\n",
        "model.add(tf.keras.layers.Embedding(input_dim=36326, output_dim = 32, mask_zero=True))\n",
        "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)))\n",
        "model.add(tf.keras.layers.Dense(9541, activation=\"softmax\"))\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(\"----- Entrainement du modèle -----\")\n",
        "model.fit(x=df_train[\"RawText\"],y= y_train, epochs=8)\n",
        "\n",
        "yhat_probs = model.predict(df_test['RawText'], verbose=0)\n",
        "y_pred = np.argmax(yhat_probs,axis=1)\n",
        "\n",
        "print(\"\\n----- Evaluation du modele : f1-Score  -----\")\n",
        "f1_score(y_test, y_pred, average='weighted')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D09I4LUkgDC2"
      },
      "source": [
        "Les résultats obtenus sont moins bons que ceux de l'exercice précédent. Ceci était prévisible pour plusieurs raisons:\n",
        "\n",
        "*   Le très grand nombre de classe.\n",
        "*   Pour certaines classes le modèle a appris que sur un exemple voir très très peu. (ce n'est pas suffisant pour qu'il puisse apprendre).\n",
        "*   Le train set contient 9248 classes or que le jeu de données intégralement en contient 9541.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYo_r8FHuRhQ"
      },
      "source": [
        "### Partie 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EvCkU0Qoo8cJ"
      },
      "outputs": [],
      "source": [
        "label_enc = preprocessing.LabelEncoder()\n",
        "label_enc.fit(df_labels)\n",
        "y_pred_decoded = label_enc.inverse_transform(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbhNpNtBvrIA"
      },
      "outputs": [],
      "source": [
        "y_test_1_carac=df_test['ICD10'].apply(lambda x: x[0])\n",
        "y_test_2_carac=df_test['ICD10'].apply(lambda x: x[0:2])\n",
        "y_test_3_carac=df_test['ICD10'].apply(lambda x: x[0:3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oF0f0s-qxxIX"
      },
      "outputs": [],
      "source": [
        "y_pred_decoded_1_carac=[x[0] for x in y_pred_decoded]\n",
        "y_pred_decoded_2_carac=[x[0:2] for x in y_pred_decoded]\n",
        "y_pred_decoded_3_carac=[x[0:3] for x in y_pred_decoded]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQgJR17BKE3n",
        "outputId": "14fe8478-3f2c-4301-ccf2-a08323a78365"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7941435265952006"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f1_score(y_test_1_carac, y_pred_decoded_1_carac, average='weighted')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIMZJBqdKP_M",
        "outputId": "7584bd8a-ea84-4192-bc6b-5b4ed7cb33be"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.733186981647169"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f1_score(y_test_2_carac, y_pred_decoded_2_carac, average='weighted')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lqdz5CBkKNv2",
        "outputId": "a4f9cd06-3145-4884-d7b2-5084022e560e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.67241344755074"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f1_score(y_test_3_carac, y_pred_decoded_3_carac, average='weighted')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "Ux25Krlnc4RZ",
        "outputId": "9524cd27-edce-4074-bfed-af1820684b51"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "df = pd.DataFrame({' ':['1 caractere', '2 caracteres','3 caracteres','4 caracteres'], 'f1_score':[0.79, 0.73, 0.67, 0.58]})\n",
        "ax = df.plot.bar(x=' ', y='f1_score', rot=0, color='maroon', figsize=(15, 5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2t9fBcBeq2E"
      },
      "source": [
        "Nous remarquons que plus le nombre de caractère augmente (augmentation du nombre de classes) plus notre f1_score diminue.  \n",
        "Cela reste cohérent, il est plus évident de prédire 26 classes que des milliers de classes. Dans notre cas, il on arrive à bien prédire la pathologie en elle même, mais plus on essaie de prédire la variante, moins on a de bons résultats."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIVEvRUrW7tz"
      },
      "source": [
        "# **Exercice 4 :** Modèle seq2seq et prédiction gloutonne du code CIM-10 à partir du langage naturel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQyOTclVUEJE"
      },
      "outputs": [],
      "source": [
        "train = df_train\n",
        "test = df_test\n",
        "val = df_val"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSfQGr9ZXDBd"
      },
      "source": [
        "## **Partie 1 : Ajustement du modèle par apprentissage forcé**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvEgdmxpZ_r2"
      },
      "source": [
        "### **Convertision des labels en séquences de texte**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "MQ4-1zf1ZJ6z",
        "outputId": "41ba7124-e3ff-418b-ec85-aef779051ac7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e9008374-96f9-4761-a7f0-1b0781269180\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RawText</th>\n",
              "      <th>ICD10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Thrombose veineuse profonde cuisse gauche</td>\n",
              "      <td>I 8 0 2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hémiplégie post-traumatique</td>\n",
              "      <td>S 0 9 9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Masculinisation avec hyperplasie surrénale</td>\n",
              "      <td>E 2 5 0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Hyperammoniémie cérébrale</td>\n",
              "      <td>E 7 2 2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Fistule artérioveineuse congénitale périphériq...</td>\n",
              "      <td>Q 2 5 7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e9008374-96f9-4761-a7f0-1b0781269180')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e9008374-96f9-4761-a7f0-1b0781269180 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e9008374-96f9-4761-a7f0-1b0781269180');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                             RawText    ICD10\n",
              "0          Thrombose veineuse profonde cuisse gauche  I 8 0 2\n",
              "1                        Hémiplégie post-traumatique  S 0 9 9\n",
              "2         Masculinisation avec hyperplasie surrénale  E 2 5 0\n",
              "3                          Hyperammoniémie cérébrale  E 7 2 2\n",
              "4  Fistule artérioveineuse congénitale périphériq...  Q 2 5 7"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train['ICD10'] = train['ICD10'].apply(lambda x : ' '.join(list(x)))\n",
        "val['ICD10'] = val['ICD10'].apply(lambda x : ' '.join(list(x)))\n",
        "test['ICD10'] = test['ICD10'].apply(lambda x : ' '.join(list(x)))\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46Bg3F7BiXlB",
        "outputId": "16b2a2a0-fa2c-41ef-b6e1-a30dd3d5efca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Nombre de mots en entrée :  32062\n",
            "Taille des vecteurs en entrée :  31 \n",
            "\n",
            "Nombre de mots en sortie :  36\n",
            "Taille des vecteurs en sortie :  5 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "unique_words_input = list(set(\" \".join(train['RawText']).lower().split(\" \")))\n",
        "num_words_input = len(unique_words_input)\n",
        "print(\"Nombre de mots en entrée : \", num_words_input)\n",
        "\n",
        "max_len_input = train.RawText.str.split(\" \").str.len().max()\n",
        "print(\"Taille des vecteurs en entrée : \", max_len_input, \"\\n\")\n",
        "\n",
        "unique_words_output = list(set(\" \".join(train['ICD10']).lower().split(\" \")))\n",
        "num_words_output = len(unique_words_output)\n",
        "print(\"Nombre de mots en sortie : \", num_words_output)\n",
        "\n",
        "max_len_output = train.ICD10.str.split(\" \").str.len().max() + 1\n",
        "print(\"Taille des vecteurs en sortie : \", max_len_output, \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5T8ptq-vBdz"
      },
      "source": [
        "### **Création des séquences d'entrée de l'encodeur, des séquences d'entrée et de sortie du décodeur**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2i9OIVFihXRg",
        "outputId": "a8d8a64a-9480-4804-808e-e5f041d75d0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Douleur dentaire, dents\n",
            "K 0 8 8 <end>\n",
            "<start> K 0 8 8\n"
          ]
        }
      ],
      "source": [
        "input_sentences_train = train['RawText'].values.tolist()\n",
        "\n",
        "list = train['ICD10'].values.tolist()\n",
        "output_sentences_inputs_train = ['<start> ' + x for x in list]\n",
        "output_sentences_train = [x + ' <end>' for x in list]\n",
        "\n",
        "\n",
        "print(input_sentences_train[17])\n",
        "print(output_sentences_train[17])\n",
        "print(output_sentences_inputs_train[17])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UWlK9XIGZv0Y"
      },
      "outputs": [],
      "source": [
        "# val data\n",
        "input_sentences_val = val['RawText'].values.tolist()\n",
        "\n",
        "list = val['ICD10'].values.tolist()\n",
        "output_sentences_inputs_val = ['<start> ' + x for x in list]\n",
        "output_sentences_val = [x + ' <end>' for x in list]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VsRwTcQiZv_e"
      },
      "outputs": [],
      "source": [
        "# test data\n",
        "input_sentences_test = test['RawText'].values.tolist()\n",
        "\n",
        "list = test['ICD10'].values.tolist()\n",
        "output_sentences_inputs_test = ['<start> ' + x for x in list]\n",
        "output_sentences_test = [x + ' <end>' for x in list]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwzjgW4qm5pL"
      },
      "source": [
        "### **Text tokenization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I85rTnSb90gP"
      },
      "source": [
        "On transforme les mots de chaque phrase en un entier. Tous les mots du jeu de données sont stockés dans un dictionnaire. Les entiers sont les clés du dictionnaire. Pour accéder aux mots dans le dictionnaire, on aura besoin de ces entiers.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRY8Lsf7WHfK"
      },
      "source": [
        "**Tokenize input sentences**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Z9SKtlhV51Z"
      },
      "outputs": [],
      "source": [
        "input_tokenizer = Tokenizer(num_words=num_words_input)\n",
        "input_tokenizer.fit_on_texts(input_sentences_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNW1pxQmkibe",
        "outputId": "e0c9a9ae-d5f6-4e40-e8f5-3025f37e2a97"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total unique words in the input: 24660\n",
            "Length of longest sentence in input: 31\n"
          ]
        }
      ],
      "source": [
        "# input sentences train\n",
        "input_integer_seq_train = input_tokenizer.texts_to_sequences(input_sentences_train)\n",
        "\n",
        "# input sentences validation\n",
        "input_integer_seq_val = input_tokenizer.texts_to_sequences(input_sentences_val)\n",
        "\n",
        "# input sentences test\n",
        "input_integer_seq_test = input_tokenizer.texts_to_sequences(input_sentences_test)\n",
        "\n",
        "\n",
        "word2idx_inputs = input_tokenizer.word_index\n",
        "print('Total unique words in the input: %s' % len(word2idx_inputs))\n",
        "\n",
        "num_words_inputs = len(word2idx_inputs) + 1\n",
        "max_input_len = max(len(sen) for sen in input_integer_seq_train)\n",
        "print(\"Length of longest sentence in input: %g\" % max_input_len)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhYoBsZ3W39n"
      },
      "source": [
        "**Tokenize output sentences**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zo-lD-cpXAZn"
      },
      "outputs": [],
      "source": [
        "output_tokenizer = Tokenizer(num_words=num_words_output, filters='')\n",
        "output_tokenizer.fit_on_texts(output_sentences_train + output_sentences_inputs_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7bUvWAilCi9",
        "outputId": "3686b223-b670-4f47-c04d-181e26b3b7f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total unique words in the output: 38\n",
            "Length of longest sentence in the output: 5\n"
          ]
        }
      ],
      "source": [
        "# output sentences train\n",
        "output_input_integer_seq_train = output_tokenizer.texts_to_sequences(output_sentences_inputs_train)\n",
        "output_integer_seq_train = output_tokenizer.texts_to_sequences(output_sentences_train)\n",
        "\n",
        "# output sentences val\n",
        "output_input_integer_seq_val = output_tokenizer.texts_to_sequences(output_sentences_inputs_val)\n",
        "output_integer_seq_val = output_tokenizer.texts_to_sequences(output_sentences_val)\n",
        "\n",
        "# output sentences test\n",
        "output_input_integer_seq_test = output_tokenizer.texts_to_sequences(output_sentences_inputs_test)\n",
        "output_integer_seq_test = output_tokenizer.texts_to_sequences(output_sentences_test)\n",
        "\n",
        "word2idx_outputs = output_tokenizer.word_index\n",
        "print('Total unique words in the output: %s' % len(word2idx_outputs))\n",
        "\n",
        "num_words_output = len(word2idx_outputs) + 1\n",
        "max_out_len = max(len(sen) for sen in output_integer_seq_train)\n",
        "print(\"Length of longest sentence in the output: %g\" % max_out_len)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ix3bxM56rhtv"
      },
      "source": [
        "### **Padding aux séquences**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgJIwG3a_aVE"
      },
      "source": [
        "On ajoute du padding (valeur 0) à chaque phrase (liste d'entiers) afin qu'elles aient la même taille que la plus grande phrase du jeu de données."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRCOcXXKYMKN"
      },
      "source": [
        "**Encode input sentences**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LT55V14lRtz",
        "outputId": "32647392-c16e-4c2c-d952-14403c19066c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "encoder_input_sequences.shape: (181763, 31)\n",
            "encoder_input_sequences[17]: [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "  460  644 1555]\n",
            "460 644 1555\n"
          ]
        }
      ],
      "source": [
        "# train data\n",
        "encoder_input_sequences_train = pad_sequences(input_integer_seq_train, maxlen=max_input_len)\n",
        "\n",
        "# val data\n",
        "encoder_input_sequences_val = pad_sequences(input_integer_seq_val, maxlen=max_input_len)\n",
        "\n",
        "# test data\n",
        "encoder_input_sequences_test = pad_sequences(input_integer_seq_test, maxlen=max_input_len)\n",
        "\n",
        "print(\"encoder_input_sequences.shape:\", encoder_input_sequences_train.shape)\n",
        "print(\"encoder_input_sequences[17]:\", encoder_input_sequences_train[17])\n",
        "print(word2idx_inputs[\"douleur\"], word2idx_inputs[\"dentaire\"], word2idx_inputs[\"dents\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ivim9HGBYP9b"
      },
      "source": [
        "**Decode input sentences**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rj916Pxal5Jl",
        "outputId": "468fe8d9-d393-4711-91c2-4f3b088d0635"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "decoder_input_sequences.shape: (181763, 5)\n",
            "decoder_input_sequences[17]: [ 2 19  4  3  3]\n",
            "2 19 4 3 3\n"
          ]
        }
      ],
      "source": [
        "# train data\n",
        "decoder_input_sequences_train = pad_sequences(output_input_integer_seq_train, maxlen=max_out_len, padding='post')\n",
        "\n",
        "# val data\n",
        "decoder_input_sequences_val = pad_sequences(output_input_integer_seq_val, maxlen=max_out_len, padding='post')\n",
        "\n",
        "# test data\n",
        "decoder_input_sequences_test = pad_sequences(output_input_integer_seq_test, maxlen=max_out_len, padding='post')\n",
        "\n",
        "\n",
        "print(\"decoder_input_sequences.shape:\", decoder_input_sequences_train.shape)\n",
        "print(\"decoder_input_sequences[17]:\", decoder_input_sequences_train[17])\n",
        "print(word2idx_outputs[\"<start>\"], word2idx_outputs[\"k\"], word2idx_outputs[\"0\"], word2idx_outputs[\"8\"], word2idx_outputs[\"8\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSDVGKGcYckM"
      },
      "source": [
        "**Decode output sequences**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hML-uFCXmVzn",
        "outputId": "86e920fe-9273-4fd5-b55e-1958edfe7014"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "decoder_output_sequences.shape: (181763, 5)\n",
            "decoder_output_sequences[171]: [19  4  3  3  1]\n",
            "19 4 3 3 1\n"
          ]
        }
      ],
      "source": [
        "# train data\n",
        "decoder_output_sequences_train = pad_sequences(output_integer_seq_train, maxlen=max_out_len, padding='post')\n",
        "\n",
        "# val data\n",
        "decoder_output_sequences_val = pad_sequences(output_integer_seq_val, maxlen=max_out_len, padding='post')\n",
        "\n",
        "# test data\n",
        "decoder_output_sequences_test = pad_sequences(output_integer_seq_test, maxlen=max_out_len, padding='post')\n",
        "\n",
        "\n",
        "print(\"decoder_output_sequences.shape:\", decoder_output_sequences_train.shape)\n",
        "print(\"decoder_output_sequences[171]:\", decoder_output_sequences_train[17])\n",
        "print(word2idx_outputs[\"k\"], word2idx_outputs[\"0\"], word2idx_outputs[\"8\"], word2idx_outputs[\"8\"], word2idx_outputs[\"<end>\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYeMiNdvXp0h"
      },
      "source": [
        "**Valeur à prédire**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GbXH6-VCuIWx"
      },
      "outputs": [],
      "source": [
        "# train data\n",
        "decoder_targets_one_hot_train = np.zeros((\n",
        "        len(input_sentences_train),\n",
        "        max_out_len,\n",
        "        num_words_output\n",
        "    ),\n",
        "    dtype='float32'\n",
        ")\n",
        "\n",
        "decoder_targets_one_hot_train.shape\n",
        "\n",
        "for i, d in enumerate(decoder_output_sequences_train):\n",
        "    for t, word in enumerate(d):\n",
        "        decoder_targets_one_hot_train[i, t, word] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sUW-7Ea7ZgPN"
      },
      "outputs": [],
      "source": [
        "# val data\n",
        "decoder_targets_one_hot_val = np.zeros((\n",
        "        len(input_sentences_val),\n",
        "        max_out_len,\n",
        "        num_words_output\n",
        "    ),\n",
        "    dtype='float32'\n",
        ")\n",
        "for i, d in enumerate(decoder_output_sequences_val):\n",
        "    for t, word in enumerate(d):\n",
        "        decoder_targets_one_hot_val[i, t, word] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sdI25wEcZgZJ"
      },
      "outputs": [],
      "source": [
        "# test data\n",
        "decoder_targets_one_hot_test = np.zeros((\n",
        "        len(input_sentences_test),\n",
        "        max_out_len,\n",
        "        num_words_output\n",
        "    ),\n",
        "    dtype='float32'\n",
        ")\n",
        "for i, d in enumerate(decoder_output_sequences_test):\n",
        "    for t, word in enumerate(d):\n",
        "        decoder_targets_one_hot_test[i, t, word] = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1az_L2_qTteF"
      },
      "source": [
        "### **Implémentation du modèle**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "funp0Ga_RLpF"
      },
      "source": [
        "**Encodeur**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2cWe3eQ2uwSb"
      },
      "outputs": [],
      "source": [
        "encoder_inputs_placeholder = Input(shape=(max_input_len,))\n",
        "\n",
        "encoder_embedding = Embedding(num_words_inputs, 256)\n",
        "x = encoder_embedding(encoder_inputs_placeholder)\n",
        "encoder = LSTM(256, return_state=True)\n",
        "\n",
        "encoder_outputs, h, c = encoder(x)\n",
        "encoder_states = [h, c]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ply97ZHdRTiV"
      },
      "source": [
        "**Décodeur**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UvoFrNnZuwY_"
      },
      "outputs": [],
      "source": [
        "decoder_inputs_placeholder = Input(shape=(max_out_len,))\n",
        "\n",
        "decoder_embedding = Embedding(num_words_output, 256)\n",
        "decoder_inputs_x = decoder_embedding(decoder_inputs_placeholder)\n",
        "\n",
        "decoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs_x, initial_state=encoder_states)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVW7dqIkTdVD"
      },
      "source": [
        "**Décodeur prédiction**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NhHwhceETT8V"
      },
      "outputs": [],
      "source": [
        "decoder_dense = Dense(num_words_output, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55GL5uKQT6pJ"
      },
      "source": [
        "### **Compilation du modèle**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fG9JGHFrvS8J"
      },
      "outputs": [],
      "source": [
        "model = Model(inputs = [encoder_inputs_placeholder, decoder_inputs_placeholder], \n",
        "              outputs = decoder_outputs\n",
        "              )\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCVmlzW2AGJ5"
      },
      "source": [
        "Dans ce modèle, on ne considère pas les prédictions relatives au padding dans la fonction objectif.\n",
        "De même, les métriques ne considèrent pas le padding dans leur estimation. Mais il aurait put être intéressant d'inclure le padding lors de l'évaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzSVuD74vTBf",
        "outputId": "cd62fd0b-856f-4bf5-b213-cd08167d7deb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "2841/2841 [==============================] - 104s 34ms/step - loss: 1.1287 - accuracy: 0.6326 - val_loss: 0.7503 - val_accuracy: 0.7623\n",
            "Epoch 2/5\n",
            "2841/2841 [==============================] - 96s 34ms/step - loss: 0.5624 - accuracy: 0.8227 - val_loss: 0.5620 - val_accuracy: 0.8254\n",
            "Epoch 3/5\n",
            "2841/2841 [==============================] - 96s 34ms/step - loss: 0.3813 - accuracy: 0.8789 - val_loss: 0.5010 - val_accuracy: 0.8487\n",
            "Epoch 4/5\n",
            "2841/2841 [==============================] - 96s 34ms/step - loss: 0.2911 - accuracy: 0.9067 - val_loss: 0.4820 - val_accuracy: 0.8582\n",
            "Epoch 5/5\n",
            "2841/2841 [==============================] - 96s 34ms/step - loss: 0.2351 - accuracy: 0.9232 - val_loss: 0.4786 - val_accuracy: 0.8635\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd07a05c450>"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(\n",
        "    [encoder_input_sequences_train, decoder_input_sequences_train], decoder_targets_one_hot_train,\n",
        "    batch_size=64,\n",
        "    epochs=5,\n",
        "    validation_data=([encoder_input_sequences_val, decoder_input_sequences_val], decoder_targets_one_hot_val),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ja_U6CR19DYS"
      },
      "source": [
        "L'entrainement du modèle sur le jeu de données de validation montre une accuracy de 86%, ce qui est très bon."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODHdcLYG1c5z",
        "outputId": "5a24c27b-720d-4c5e-fac8-24c28953be2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "469/469 [==============================] - 5s 11ms/step - loss: 0.4754 - accuracy: 0.8644\n",
            "test loss, test acc: [0.47539907693862915, 0.864359974861145]\n"
          ]
        }
      ],
      "source": [
        "results = model.evaluate([encoder_input_sequences_test, decoder_input_sequences_test], decoder_targets_one_hot_test, batch_size=64)\n",
        "print(\"test loss, test acc:\", results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOqPpvTrFVx1"
      },
      "source": [
        "  L'évaluation du modèle sur le jeu de données de test montre une accuracy de 86%. Le modèle a de bonnes performances"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSUdeDjXGyE-"
      },
      "source": [
        "### **Enregistrement des poids du modèle**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mP0LvsOoDz7E"
      },
      "outputs": [],
      "source": [
        "checkpoint_path = \"training_1/cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Create a callback that saves the model's weights\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)\n",
        "\n",
        "\n",
        "# Save the weights using the `checkpoint_path` format\n",
        "model.save_weights(checkpoint_path.format(epoch=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBBEJheuDYnn",
        "outputId": "fac3e12e-8b03-41e6-b9b2-5014942eac87"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fd04f907850>"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Loads the weights\n",
        "model.load_weights(checkpoint_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SXT-lZJMPdf"
      },
      "source": [
        "## **Partie : 2 Prédictions gloutonnes à partir d’un modèle ajusté**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0DN8GW1x979"
      },
      "outputs": [],
      "source": [
        "idx2word_target = {v:k for k, v in word2idx_outputs.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9UAVksflyOEa"
      },
      "outputs": [],
      "source": [
        "# function to predict code ICD10\n",
        "# input_seq : input sequence in the encoder, patient symptoms\n",
        "# return code ICD10\n",
        "def predict_sequence(input_seq):\n",
        "\n",
        "    # first word of the output sentence\n",
        "    output_sentence = ['<start>']\n",
        "\n",
        "    # transform each text in texts to a sequence of integers\n",
        "    # padding 0 in the sequence until it has the same length as the longest input sequence in the model\n",
        "    input_in = input_tokenizer.texts_to_sequences([input_seq])\n",
        "    encoder_input_sequence = pad_sequences(input_in, maxlen=max_input_len)\n",
        "\n",
        "    for i in range(max_out_len -1):\n",
        "      # transform each text in texts to a sequence of integers\n",
        "      # padding 0 in the sequence until it has the same length as the longest output sequence in the model\n",
        "      output_in = output_tokenizer.texts_to_sequences(output_sentence)\n",
        "      decoder_input_sequences = pad_sequences(output_in, maxlen=max_out_len, padding='post')\n",
        "\n",
        "      # predict code IDC10 based on the input sentence and the previous output from the decoder\n",
        "      output_tokens = model.predict([encoder_input_sequence, decoder_input_sequences])\n",
        "\n",
        "      # get the word with the highest probability\n",
        "      idx = np.argmax(output_tokens[0, i, :])\n",
        "      word = idx2word_target[idx]\n",
        "\n",
        "      # concanate the predicted word with the previous sentence predicted\n",
        "      output_sentence.append(word) \n",
        "      output_sentence = [' '.join(output_sentence)]\n",
        "\n",
        "    # remove fist element <start>\n",
        "    final_output = ''.join(output_sentence)\n",
        "    final_output = final_output.split()\n",
        "    final_output.pop(0)\n",
        "\n",
        "    return ''.join(final_output).upper()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbEu-kWLyOUM",
        "outputId": "6b46c55e-4cc7-4844-a1e6-9b1a3f254cc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: Thrombose veineuse profonde cuisse gauche\n",
            "Output: I802\n"
          ]
        }
      ],
      "source": [
        "# Exemple de la prédiction d'un code ICD10 à partir d'une phrase\n",
        "\n",
        "input_seq = 'Thrombose veineuse profonde cuisse gauche'\n",
        "\n",
        "output_seq = predict_sequence(input_seq)\n",
        "\n",
        "print('Input:', input_seq)\n",
        "print('Output:', output_seq)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ud44BvZWElJP"
      },
      "source": [
        "### **Prédiction gloutonne sur le jeu de données de validation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VhP6o2BbBEeo",
        "outputId": "6061781a-62bd-4f27-fae3-9920fa68bea4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.5130666666666667"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "for i in range(len(val['RawText'])):\n",
        "  input_seq = val['RawText'][i]\n",
        "\n",
        "  expected_seq = val['ICD10'][i].replace(\" \", \"\")\n",
        "  y_true.append(expected_seq)\n",
        "\n",
        "  output_seq = predict_sequence(input_seq)\n",
        "  y_pred.append(output_seq)\n",
        "\n",
        "f1_score(y_true,y_pred, average='weighted')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMIpzVhWNKRD"
      },
      "source": [
        "Avec la prédiction gloutonne, on a un f1-score de 51%, ce qui est plus faible que le modèle de classification classique ajusté précédemment. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzBCq_7epCWd"
      },
      "source": [
        "# **Exercice 5 :** Pour aller plus loin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vu_JgJgm6Hzg"
      },
      "source": [
        "## Point 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47qSBa-JhTWT"
      },
      "source": [
        "Dans le but d'améliorer notre modèle, nous allons effectuer un nettoyage de texte, puis réexécuter nos algorithmes et comparer les résultats."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plOx4hJpHHJw"
      },
      "source": [
        "### Install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3b2GPrWM7SgI",
        "outputId": "2bfd6259-1e6a-4e7d-fb64-4baf0b5ab1d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9W4Bl9dkkgpE",
        "outputId": "6eba01f0-4047-40b0-8008-622143336f52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.6)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.4.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.6)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.62.3)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (4.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy) (3.6.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CYaieQayyIY",
        "outputId": "ce857aa3-3c33-4b6f-9cc5-bf797acadf47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting fr_core_news_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-2.2.5/fr_core_news_sm-2.2.5.tar.gz (14.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.7 MB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from fr_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (4.62.3)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.6)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.0.6)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.0.6)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_sm==2.2.5) (4.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.6.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.10)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('fr_core_news_sm')\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download fr_core_news_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHfgNHdlzfvW",
        "outputId": "edf2a465-0cea-457b-cdaa-8615a45d063e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting fr_core_news_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-2.2.5/fr_core_news_sm-2.2.5.tar.gz (14.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.7 MB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from fr_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (4.62.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.0.6)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.0.6)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_sm==2.2.5) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.10.0.2)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->fr_core_news_sm==2.2.5) (2021.10.8)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('fr_core_news_sm')\n"
          ]
        }
      ],
      "source": [
        "!spacy download fr_core_news_sm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1M9FaHf6G5Hn"
      },
      "source": [
        "### Nettoyage du texte"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3-D_mnwkgyM"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "import spacy\n",
        "import fr_core_news_sm\n",
        "\n",
        "from nltk.stem.snowball import SnowballStemmer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_28p-hLmW_m"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load(\"fr_core_news_sm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mm3ze9PbmjHz",
        "outputId": "34e42f72-ac01-4126-c77b-ebc8f6e785f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4DEXq9886HJA"
      },
      "outputs": [],
      "source": [
        "stop_words = stopwords.words('french')\n",
        "\n",
        "def clean_text(\n",
        "    string: str,\n",
        "    punctuations=r'''!()-[]{};:'\"\\,<>./?@#$%^&*_~''',\n",
        "    stop_words=stop_words) -> str:\n",
        "    \"\"\"\n",
        "    A method to clean text - preprocessing\n",
        "    \"\"\"\n",
        "    #Cleaning the urls\n",
        "    string = re.sub(r'https?://\\S+|www\\.\\S+','',string)\n",
        "\n",
        "    #Cleaning the html elements\n",
        "    string = re.sub(r'<.*?>','',string)\n",
        "\n",
        "    #Cleaning numbers\n",
        "    #string = re.sub(r'[0-9]+','',string)\n",
        "\n",
        "    #Removing the punctuations\n",
        "    for x in string.lower():\n",
        "      if x in punctuations:\n",
        "        string = string.replace(x,\"\")\n",
        "    \n",
        "    #Converting to the text to lower\n",
        "    string = string.lower()\n",
        "\n",
        "    #Removing stop words\n",
        "    string = ' '.join([word for word in string.split() if word not in stop_words])\n",
        "    \n",
        "    #Cleaning the whitespaces\n",
        "    string = re.sub(r'\\s+', ' ', string).strip()\n",
        "\n",
        "    #Lemmatization\n",
        "    stemmer = SnowballStemmer(language='french')\n",
        "    doc = nlp(string)\n",
        "    string_final = ' '.join([stemmer.stem(token.text) for token in doc])\n",
        "  \n",
        "    return string_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OovDz9NjgbO9"
      },
      "outputs": [],
      "source": [
        "df_list=[clean_text(x) for x in df_train['RawText'].astype(str)]\n",
        "df_train = pd.DataFrame(list(zip(df_list, list(df_train['ICD10']))), columns =['RawText', 'ICD10'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oCYO8cJamn2J"
      },
      "outputs": [],
      "source": [
        "df_list=[clean_text(x) for x in df_test['RawText'].astype(str)]\n",
        "df_test = pd.DataFrame(list(zip(df_list, list(df_test['ICD10']))), columns =['RawText', 'ICD10'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r-1JjuwtrswC"
      },
      "outputs": [],
      "source": [
        "df_list=[clean_text(x) for x in df_val['RawText'].astype(str)]\n",
        "df_val = pd.DataFrame(list(zip(df_list, list(df_val['ICD10']))), columns =['RawText', 'ICD10'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ig-U_14tDXF5"
      },
      "source": [
        "### Classification du premier caractère du code CIM-10 à partir du langage naturel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01ovzqayDCks"
      },
      "outputs": [],
      "source": [
        "df_train['ICD10_1_Carac']=df_train['ICD10'].apply(lambda x: x[0])\n",
        "df_test['ICD10_1_Carac']=df_test['ICD10'].apply(lambda x: x[0])\n",
        "df_val['ICD10_1_Carac']=df_val['ICD10'].apply(lambda x: x[0])\n",
        "\n",
        "df_train['ICD10_1_Carac']=preprocessing.LabelEncoder().fit_transform(df_train.ICD10_1_Carac.values)\n",
        "df_test['ICD10_1_Carac']=preprocessing.LabelEncoder().fit_transform(df_test.ICD10_1_Carac.values)\n",
        "df_val['ICD10_1_Carac']=preprocessing.LabelEncoder().fit_transform(df_val.ICD10_1_Carac.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwhQRplKDJSa",
        "outputId": "f49a139e-b5ac-40aa-d9fd-3f86fc167728"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----- Entrainement du modèle -----\n",
            "Epoch 1/5\n",
            "5681/5681 [==============================] - 97s 16ms/step - loss: 1.2264 - accuracy: 0.6675 - val_loss: 0.7446 - val_accuracy: 0.7912\n",
            "Epoch 2/5\n",
            "5681/5681 [==============================] - 93s 16ms/step - loss: 0.6048 - accuracy: 0.8260 - val_loss: 0.6154 - val_accuracy: 0.8204\n",
            "Epoch 3/5\n",
            "5681/5681 [==============================] - 90s 16ms/step - loss: 0.4728 - accuracy: 0.8555 - val_loss: 0.5845 - val_accuracy: 0.8229\n",
            "Epoch 4/5\n",
            "5681/5681 [==============================] - 86s 15ms/step - loss: 0.4132 - accuracy: 0.8668 - val_loss: 0.5640 - val_accuracy: 0.8284\n",
            "Epoch 5/5\n",
            "5681/5681 [==============================] - 91s 16ms/step - loss: 0.3781 - accuracy: 0.8749 - val_loss: 0.5588 - val_accuracy: 0.8293\n",
            "----- Evaluation du modele : accuracy -----\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.5544 - accuracy: 0.8304\n",
            "----- Evaluation du modele : recall -----\n",
            "938/938 [==============================] - 6s 7ms/step - loss: 0.5544 - accuracy: 0.8304\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.5544145703315735, 0.8304333090782166]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vectorize_layer = tf.keras.layers.TextVectorization(max_tokens=28970, output_mode='int')\n",
        "\n",
        "vectorize_layer.adapt(df_train[\"RawText\"])\n",
        "\n",
        "#Construction de notre réseau de neuronne \n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "model.add(tf.keras.Input(shape=(1,), dtype=tf.string))\n",
        "model.add(vectorize_layer)\n",
        "model.add(tf.keras.layers.Embedding(28970, output_dim=32, mask_zero=True))\n",
        "model.add(tf.keras.layers.LSTM(32, dropout=0.1))\n",
        "model.add( tf.keras.layers.Dense(26,activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(\"----- Entrainement du modèle -----\")\n",
        "model.fit(x=df_train[\"RawText\"],y= df_train['ICD10_1_Carac'], epochs=5, validation_data=(df_val['RawText'], df_val['ICD10_1_Carac']))\n",
        "\n",
        "print(\"----- Evaluation du modele : accuracy -----\")\n",
        "model.evaluate(df_test['RawText'],df_test['ICD10_1_Carac'])\n",
        "\n",
        "print(\"----- Evaluation du modele : recall -----\")\n",
        "model.evaluate(df_test['RawText'],df_test['ICD10_1_Carac'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7G2GLX2unmX",
        "outputId": "49f70055-bfe6-4a9e-dacf-d3ae6aaffc14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "----- Evaluation du modele : f1-Score  -----\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.8309936201163005"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "yhat_probs = model.predict(df_test['RawText'], verbose=0)\n",
        "y_pred = np.argmax(yhat_probs,axis=1)\n",
        "\n",
        "print(\"\\n----- Evaluation du modele : f1-Score  -----\")\n",
        "f1_score(df_test['ICD10_1_Carac'].to_numpy(), y_pred, average='weighted')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-NX6t-UxwBe"
      },
      "source": [
        "Nous constatons, que malgré notre amélioration de la méthode de nettoyage du texte, nous n'avons pas forcément obtenu de meilleurs résultats."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHGF1W7mGV4o"
      },
      "source": [
        "### Classification du code CIM-10 entier à partir du langage naturel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLC-NNY3GXTA"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv(\"train.csv\")\n",
        "df_test = pd.read_csv(\"test.csv\")\n",
        "df_val = pd.read_csv(\"val.csv\")\n",
        "\n",
        "df_labels=pd.concat([df_train['ICD10'], df_test['ICD10'],df_val['ICD10']])\n",
        "labels=preprocessing.LabelEncoder().fit_transform(df_labels)\n",
        "\n",
        "y_train = labels[:181763]\n",
        "y_test = labels[181763:211763]\n",
        "y_val = labels[211763:241763]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIw0PL6qhGvs",
        "outputId": "6349d59a-2c0f-4542-a66b-03a83dfd82d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----- Entrainement du modèle -----\n",
            "Epoch 1/8\n",
            "5681/5681 [==============================] - 173s 29ms/step - loss: 6.8534 - accuracy: 0.0722\n",
            "Epoch 2/8\n",
            "5681/5681 [==============================] - 154s 27ms/step - loss: 4.1446 - accuracy: 0.2951\n",
            "Epoch 3/8\n",
            "5681/5681 [==============================] - 148s 26ms/step - loss: 2.7732 - accuracy: 0.4652\n",
            "Epoch 4/8\n",
            "5681/5681 [==============================] - 164s 29ms/step - loss: 2.0255 - accuracy: 0.5791\n",
            "Epoch 5/8\n",
            "5681/5681 [==============================] - 147s 26ms/step - loss: 1.5645 - accuracy: 0.6559\n",
            "Epoch 6/8\n",
            "5681/5681 [==============================] - 153s 27ms/step - loss: 1.2563 - accuracy: 0.7093\n",
            "Epoch 7/8\n",
            "5681/5681 [==============================] - 146s 26ms/step - loss: 1.0460 - accuracy: 0.7469\n",
            "Epoch 8/8\n",
            "5681/5681 [==============================] - 143s 25ms/step - loss: 0.8948 - accuracy: 0.7744\n",
            "\n",
            "----- Evaluation du modele : f1-Score  -----\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.5845924508323891"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vectorize_layer = tf.keras.layers.TextVectorization(max_tokens=36326, output_mode='int')\n",
        "\n",
        "vectorize_layer.adapt(df_train[\"RawText\"])\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.Input(shape=(1,), dtype=tf.string))\n",
        "model.add(vectorize_layer)\n",
        "model.add(tf.keras.layers.Embedding(input_dim=36326, output_dim = 32, mask_zero=True))\n",
        "model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)))\n",
        "model.add(tf.keras.layers.Dense(9541, activation=\"softmax\"))\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(\"----- Entrainement du modèle -----\")\n",
        "model.fit(x=df_train[\"RawText\"],y= y_train, epochs=8)\n",
        "\n",
        "yhat_probs = model.predict(df_test['RawText'], verbose=0)\n",
        "y_pred = np.argmax(yhat_probs,axis=1)\n",
        "\n",
        "print(\"\\n----- Evaluation du modele : f1-Score  -----\")\n",
        "f1_score(y_test, y_pred, average='weighted')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_j8w0-yL25cQ"
      },
      "source": [
        "Pareil ici, nous constatons que malgré notre amélioration de la méthode de nettoyage du texte, nous n'avons pas forcément obtenu de meilleurs résultats."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihwYOlzIpEoe"
      },
      "source": [
        "## Point 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WchGbtrSwDaq"
      },
      "source": [
        "### Initialisation du tokenizer. Création du vocabulaire à partir des données d'entrainement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8iga70dpPc0"
      },
      "outputs": [],
      "source": [
        "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(df_train.RawText, target_vocab_size=2**13)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pmn8xqtpHE1",
        "outputId": "37c61a26-e4eb-4007-da63-1facc0cf4ca6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bronchopneumo fulminante enterobacter\n",
            "[1911, 100, 7933, 4860, 3667]\n"
          ]
        }
      ],
      "source": [
        "print(\"bronchopneumo fulminante enterobacter\")\n",
        "test_tokens = tokenizer.encode(\"pneumocardio fulminante enterobacter\")\n",
        "print(test_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52ydXN0ExD8g",
        "outputId": "9ac5ac27-6b29-459e-ef03-0e1d5f8f353a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pneumo\n",
            "cardio\n",
            " \n",
            "fulminante \n",
            "enterobacter\n"
          ]
        }
      ],
      "source": [
        "for token in test_tokens:\n",
        "  print(tokenizer.decode([token]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4R_Fqxhw3Eg"
      },
      "source": [
        "On voit que le tokenizer arrive à decomposer \"pneumocardio\" en deux sous-mots \"pneumo\" et \"cardio\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2Zt5wBEqlmU"
      },
      "outputs": [],
      "source": [
        "# Transforme une liste de strings en liste de vecteurs\n",
        "def tokenize(tokenizer, data):\n",
        "  tokenized_data = []\n",
        "  for row in data:\n",
        "    tokenized_data.append(tokenizer.encode(row))\n",
        "  return tokenized_data\n",
        "\n",
        "# Transforme une liste de vecteurs en liste de strings \n",
        "def detokenize(tokenizer, tokenized_data):\n",
        "  data = []\n",
        "  for row in tokenized_data:\n",
        "    data.append(tokenizer.decode(row))\n",
        "  return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFNFNx4urYKH",
        "outputId": "2c400a32-1de1-4b0f-9252-8648d4389839"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[40, 203, 674, 354, 5], [741, 16, 7946, 136], [1955, 1958, 7, 3850, 2446]]\n",
            "['thrombose veineuse profonde cuisse gauche', 'hémiplégie post-traumatique', 'masculinisation avec hyperplasie surrénale']\n"
          ]
        }
      ],
      "source": [
        "# Test des methodes avec les 3 premières lignes des données d'entrainement\n",
        "\n",
        "tokenized_data = tokenize(tokenizer, df_train['RawText'][:3].values.tolist())\n",
        "print(tokenized_data)\n",
        "detokenized_data = detokenize(tokenizer, tokenized_data)\n",
        "print(detokenized_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9eZ7XiRHP4L"
      },
      "source": [
        "### Tokenisation des différents jeux de données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oNtHhIl0HP4N"
      },
      "outputs": [],
      "source": [
        "train_data = tokenize(tokenizer, df_train['RawText'].values.tolist())\n",
        "test_data = tokenize(tokenizer, df_test['RawText'].values.tolist())\n",
        "vzl_data = tokenize(tokenizer, df_val['RawText'].values.tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_DP1SBcHP4Q"
      },
      "source": [
        "On ajoute un padding pour que tous les datasets aient les mêmes dimensions afin de pouvoir utiliser les modèles de keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IIsySvfBHP4S"
      },
      "outputs": [],
      "source": [
        "max_len = np.max([pd.Series(train_data).str.len().max(),\n",
        "                  pd.Series(test_data).str.len().max(),\n",
        "                  pd.Series(vzl_data).str.len().max()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W6FnqmyuHP4U"
      },
      "outputs": [],
      "source": [
        "train_data = pad_sequences(train_data, maxlen=max_len, padding='post')\n",
        "test_data = pad_sequences(test_data, maxlen=max_len, padding='post')\n",
        "val_data = pad_sequences(vzl_data, maxlen=max_len, padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Wr8NuqbriWG"
      },
      "outputs": [],
      "source": [
        "x_train = tf.expand_dims(train_data, axis=1)\n",
        "x_test = tf.expand_dims(test_data, axis=1)\n",
        "x_val = tf.expand_dims(val_data, axis=1)\n",
        "\n",
        "\n",
        "y_train = tf.expand_dims(df_train['ICD10_1_Carac'], axis=1)\n",
        "y_test = tf.expand_dims(df_test['ICD10_1_Carac'], axis=1)\n",
        "y_val = tf.expand_dims(df_val['ICD10_1_Carac'], axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30dLK4ftl_PP"
      },
      "source": [
        "### Entrainement du modèle avec le nouveau jeu de données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2EW3a8eDl5LG",
        "outputId": "415be0ac-53b7-4590-ae55-fa84270dd282"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----- Entrainement du modèle -----\n",
            "Epoch 1/15\n",
            "5681/5681 [==============================] - 75s 11ms/step - loss: 1.6604 - accuracy: 0.5333 - val_loss: 1.0522 - val_accuracy: 0.7105\n",
            "Epoch 2/15\n",
            "5681/5681 [==============================] - 62s 11ms/step - loss: 0.9607 - accuracy: 0.7309 - val_loss: 0.8378 - val_accuracy: 0.7657\n",
            "Epoch 3/15\n",
            "5681/5681 [==============================] - 62s 11ms/step - loss: 0.8051 - accuracy: 0.7680 - val_loss: 0.7507 - val_accuracy: 0.7855\n",
            "Epoch 4/15\n",
            "5681/5681 [==============================] - 62s 11ms/step - loss: 0.7266 - accuracy: 0.7858 - val_loss: 0.6954 - val_accuracy: 0.7963\n",
            "Epoch 5/15\n",
            "5681/5681 [==============================] - 68s 12ms/step - loss: 0.6721 - accuracy: 0.7987 - val_loss: 0.6667 - val_accuracy: 0.8042\n",
            "Epoch 6/15\n",
            "5681/5681 [==============================] - 62s 11ms/step - loss: 0.6339 - accuracy: 0.8071 - val_loss: 0.6425 - val_accuracy: 0.8089\n",
            "Epoch 7/15\n",
            "5681/5681 [==============================] - 62s 11ms/step - loss: 0.6048 - accuracy: 0.8151 - val_loss: 0.6255 - val_accuracy: 0.8124\n",
            "Epoch 8/15\n",
            "5681/5681 [==============================] - 69s 12ms/step - loss: 0.5827 - accuracy: 0.8200 - val_loss: 0.6141 - val_accuracy: 0.8142\n",
            "Epoch 9/15\n",
            "5681/5681 [==============================] - 89s 16ms/step - loss: 0.5613 - accuracy: 0.8248 - val_loss: 0.6032 - val_accuracy: 0.8176\n",
            "Epoch 10/15\n",
            "5681/5681 [==============================] - 62s 11ms/step - loss: 0.5448 - accuracy: 0.8289 - val_loss: 0.5951 - val_accuracy: 0.8189\n",
            "Epoch 11/15\n",
            "5681/5681 [==============================] - 62s 11ms/step - loss: 0.5306 - accuracy: 0.8317 - val_loss: 0.5879 - val_accuracy: 0.8205\n",
            "Epoch 12/15\n",
            "5681/5681 [==============================] - 62s 11ms/step - loss: 0.5193 - accuracy: 0.8353 - val_loss: 0.5852 - val_accuracy: 0.8223\n",
            "Epoch 13/15\n",
            "5681/5681 [==============================] - 62s 11ms/step - loss: 0.5106 - accuracy: 0.8373 - val_loss: 0.5827 - val_accuracy: 0.8224\n",
            "Epoch 14/15\n",
            "5681/5681 [==============================] - 63s 11ms/step - loss: 0.5011 - accuracy: 0.8393 - val_loss: 0.5717 - val_accuracy: 0.8251\n",
            "Epoch 15/15\n",
            "5681/5681 [==============================] - 62s 11ms/step - loss: 0.4908 - accuracy: 0.8416 - val_loss: 0.5688 - val_accuracy: 0.8274\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f62101eba90>"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "from keras.layers import Dense, LayerNormalization, LSTM, Embedding, GlobalAveragePooling1D, TextVectorization, Conv1D, Flatten\n",
        "\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "                             Embedding(input_dim=8096, output_dim=30, mask_zero=True, input_length=max_len),\n",
        "                             LSTM(30, dropout=0.2, recurrent_dropout=0., return_sequences=True),\n",
        "                             LSTM(30, dropout=0.2, recurrent_dropout=0., return_sequences=True),\n",
        "                             GlobalAveragePooling1D(),\n",
        "                             Dense(nbre_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(\"----- Entrainement du modèle -----\")\n",
        "model.fit(train_data, y_train, epochs=15, batch_size=32, validation_data=(val_data, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F446DBmIAa7M",
        "outputId": "99c2f50c-fb1d-4d22-ae26-691325422d44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "----- Evaluation du modele  -----\n",
            "938/938 [==============================] - 4s 4ms/step - loss: 0.5570 - accuracy: 0.8320\n",
            "Accuracy: 0.8320333361625671\n",
            "\n",
            "----- Evaluation du modele : f1-Score  -----\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.8290298193182769"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"\\n----- Evaluation du modele  -----\")\n",
        "print(\"Accuracy:\", model.evaluate(test_data, y_test)[1])\n",
        "\n",
        "yhat_probs = model.predict(test_data, verbose=0)\n",
        "y_pred = np.argmax(yhat_probs,axis=1)\n",
        "\n",
        "print(\"\\n----- Evaluation du modele : f1-Score  -----\")\n",
        "f1_score(y_test, y_pred, average='weighted')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdXaoBtHHrgt"
      },
      "source": [
        "On remarque que pour notre problème, decomposer le texte en sous mots améliore légèrement le résultat obtenu. En effet on obtient des métriques similaires à celles que l'on avait quand on tokenisait les documents seul, mais on peut aussi constater que le modèle n'a pas tendance à sur-apprendre malgré le nombre d'epochs élevé, ce qui n'était pas le cas avec le modèle vu plus haut. Toutefois, les points gagnés en terme de performance de modèle se compensent avec le temps d'entrainement qu'on pourrait juger un peu long."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTExj2Q6Vkjc"
      },
      "source": [
        "## Point 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxlr5xx-gM4r"
      },
      "source": [
        "Une convolution standard ne prenant pas en compte la direction de"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvYe-TAOVngS",
        "outputId": "2c91bb73-3a73-40a8-e4e7-bd25fd4dc63e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "5681/5681 [==============================] - 31s 5ms/step - loss: 3.0295 - accuracy: 0.1217\n",
            "Epoch 2/5\n",
            "5681/5681 [==============================] - 25s 4ms/step - loss: 2.9965 - accuracy: 0.1301\n",
            "Epoch 3/5\n",
            "5681/5681 [==============================] - 26s 5ms/step - loss: 2.9926 - accuracy: 0.1304\n",
            "Epoch 4/5\n",
            "5681/5681 [==============================] - 26s 5ms/step - loss: 2.9858 - accuracy: 0.1319\n",
            "Epoch 5/5\n",
            "5681/5681 [==============================] - 27s 5ms/step - loss: 2.9869 - accuracy: 0.1314\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6212e58dd0>"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "                             keras.layers.Conv1D(32, 5, padding='causal', strides=2, input_shape=x.shape[1:]),\n",
        "                             keras.layers.Conv1D(32, 5, padding='causal', strides=2),\n",
        "                             LSTM(30, dropout=0.2, recurrent_dropout=0., return_sequences=True),\n",
        "                             #keras.layers.GlobalAveragePooling1D(),\n",
        "                             keras.layers.Dense(nbre_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(x, y_train, epochs=5) #,batch_size=32, validation_data=(x_val, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUZGmpoqbAq-",
        "outputId": "4e20541b-5c2d-40a7-b680-53577c79b763"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "----- Evaluation du modele  -----\n",
            "938/938 [==============================] - 3s 3ms/step - loss: 2.9992 - accuracy: 0.1265\n",
            "Accuracy: 0.1264999955892563\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n----- Evaluation du modele  -----\")\n",
        "x_test = tf.expand_dims(test_data, axis=1)\n",
        "print(\"Accuracy:\", model.evaluate(x_test, y_test)[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N15AD6-0FLPm"
      },
      "source": [
        "## Point 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvhRhxr9FO-d",
        "outputId": "0e705d0e-4e99-4d8f-cd62-92641e125bf6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorflow_text\n",
            "  Downloading tensorflow_text-2.7.3-cp37-cp37m-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (0.12.0)\n",
            "Requirement already satisfied: tensorflow<2.8,>=2.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (2.7.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.1.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (3.1.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (3.17.3)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.19.5)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (2.7.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (0.22.0)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (2.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (12.0.0)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (2.7.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.15.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.6.3)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (0.12.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.13.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (3.10.0.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (0.37.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (2.7.0)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.42.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (3.3.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.5.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (3.3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (0.4.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (57.4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (3.1.1)\n",
            "Installing collected packages: tensorflow-text\n",
            "Successfully installed tensorflow-text-2.7.3\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_wjt1Cmhsir7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "import typing\n",
        "from typing import Any, Tuple\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_text as tf_text\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ic6ejFxnPQv"
      },
      "outputs": [],
      "source": [
        "inp = train['RawText'].values.tolist()\n",
        "targ = train['ICD10'].values.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YaloWMg_A_Us"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = len(inp)\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((inp, targ)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sf-aq5bKpXIv"
      },
      "outputs": [],
      "source": [
        "#Pré-traitement du texte\n",
        "def tf_lower_and_split_punct(text):\n",
        "  # Split accecented characters.\n",
        "  text = tf_text.normalize_utf8(text, 'NFKD')\n",
        "  text = tf.strings.lower(text)\n",
        "  # Strip whitespace.\n",
        "  text = tf.strings.strip(text)\n",
        "\n",
        "  text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQ83Tp-nnm54"
      },
      "outputs": [],
      "source": [
        "#Vectorisation du texte\n",
        "max_vocab_size = 5000\n",
        "\n",
        "input_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyjzZrw2oaA5",
        "outputId": "3fd9d5e4-a03a-496f-87c9-2322f3da98af"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['', '[UNK]', '[START]', '[END]', 'de', 'aussi', 'voir', 'gauche', 'nca', 'à']"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#La méthode adapt initialise la couche sur la base des données. Ici, il détermine le vocabulaire\n",
        "input_text_processor.adapt(inp)\n",
        "\n",
        "#Voici les 10 premiers mots du vocabulaire :\n",
        "input_text_processor.get_vocabulary()[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1k2toTIpn9m",
        "outputId": "7e47ffaa-7f81-4d9f-e37d-07170b5bb9be"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['',\n",
              " '[UNK]',\n",
              " '[START]',\n",
              " '[END]',\n",
              " 's062',\n",
              " 'c798',\n",
              " 'c859',\n",
              " 'c349',\n",
              " 'z924',\n",
              " 'i251']"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#C'est le text 'TextVectorization' couche, construire maintenant avec .adapt() les classes \n",
        "output_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size)\n",
        "\n",
        "output_text_processor.adapt(targ)\n",
        "output_text_processor.get_vocabulary()[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "izUkpcE2pehZ"
      },
      "outputs": [],
      "source": [
        "embedding_dim = 256\n",
        "units = 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KqFqKi4fqN9X"
      },
      "outputs": [],
      "source": [
        "#@title Shape checker\n",
        "class ShapeChecker():\n",
        "  def __init__(self):\n",
        "    # Keep a cache of every axis-name seen\n",
        "    self.shapes = {}\n",
        "\n",
        "  def __call__(self, tensor, names, broadcast=False):\n",
        "    if not tf.executing_eagerly():\n",
        "      return\n",
        "\n",
        "    if isinstance(names, str):\n",
        "      names = (names,)\n",
        "\n",
        "    shape = tf.shape(tensor)\n",
        "    rank = tf.rank(tensor)\n",
        "\n",
        "    if rank != len(names):\n",
        "      raise ValueError(f'Rank mismatch:\\n'\n",
        "                       f'    found {rank}: {shape.numpy()}\\n'\n",
        "                       f'    expected {len(names)}: {names}\\n')\n",
        "\n",
        "    for i, name in enumerate(names):\n",
        "      if isinstance(name, int):\n",
        "        old_dim = name\n",
        "      else:\n",
        "        old_dim = self.shapes.get(name, None)\n",
        "      new_dim = shape[i]\n",
        "\n",
        "      if (broadcast and new_dim == 1):\n",
        "        continue\n",
        "\n",
        "      if old_dim is None:\n",
        "        # If the axis name is new, add its length to the cache.\n",
        "        self.shapes[name] = new_dim\n",
        "        continue\n",
        "\n",
        "      if new_dim != old_dim:\n",
        "        raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\n",
        "                         f\"    found: {new_dim}\\n\"\n",
        "                         f\"    expected: {old_dim}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HeAgTCDYp-39"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "  '''\n",
        "  return : \n",
        "      output : la séquence traitée.\n",
        "      stat : l'état interne qui sera utilisé pour initialiser le décodeur.\n",
        "  '''\n",
        "  def __init__(self, input_vocab_size, embedding_dim, enc_units):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.enc_units = enc_units\n",
        "    self.input_vocab_size = input_vocab_size\n",
        "\n",
        "    # The embedding layer converts tokens to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.input_vocab_size,\n",
        "                                               embedding_dim)\n",
        "\n",
        "    # The GRU RNN layer processes those vectors sequentially.\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   # Return the sequence and state\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "  def call(self, tokens, state=None):\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(tokens, ('batch', 's'))\n",
        "\n",
        "    # 2. The embedding layer looks up the embedding for each token.\n",
        "    vectors = self.embedding(tokens)\n",
        "    shape_checker(vectors, ('batch', 's', 'embed_dim'))\n",
        "\n",
        "    # 3. The GRU processes the embedding sequence.\n",
        "    #    output shape: (batch, s, enc_units)\n",
        "    #    state shape: (batch, enc_units)\n",
        "    output, state = self.gru(vectors, initial_state=state)\n",
        "    shape_checker(output, ('batch', 's', 'enc_units'))\n",
        "    shape_checker(state, ('batch', 'enc_units'))\n",
        "\n",
        "    # 4. Returns the new sequence and its state.\n",
        "    return output, state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HnqvMSbMqP-Z"
      },
      "outputs": [],
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super().__init__()\n",
        "    # For Eqn. (4), the  Bahdanau attention\n",
        "    self.W1 = tf.keras.layers.Dense(units, use_bias=False)\n",
        "    self.W2 = tf.keras.layers.Dense(units, use_bias=False)\n",
        "\n",
        "    self.attention = tf.keras.layers.AdditiveAttention()\n",
        "\n",
        "  def call(self, query, value, mask):\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(query, ('batch', 't', 'query_units'))\n",
        "    shape_checker(value, ('batch', 's', 'value_units'))\n",
        "    shape_checker(mask, ('batch', 's'))\n",
        "\n",
        "    # From Eqn. (4), `W1@ht`.\n",
        "    w1_query = self.W1(query)\n",
        "    shape_checker(w1_query, ('batch', 't', 'attn_units'))\n",
        "\n",
        "    # From Eqn. (4), `W2@hs`.\n",
        "    w2_key = self.W2(value)\n",
        "    shape_checker(w2_key, ('batch', 's', 'attn_units'))\n",
        "\n",
        "    query_mask = tf.ones(tf.shape(query)[:-1], dtype=bool)\n",
        "    value_mask = mask\n",
        "\n",
        "    context_vector, attention_weights = self.attention(\n",
        "        inputs = [w1_query, value, w2_key],\n",
        "        mask=[query_mask, value_mask],\n",
        "        return_attention_scores = True,\n",
        "    )\n",
        "    shape_checker(context_vector, ('batch', 't', 'value_units'))\n",
        "    shape_checker(attention_weights, ('batch', 't', 's'))\n",
        "\n",
        "    return context_vector, attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w3jD0GMHtfq0"
      },
      "outputs": [],
      "source": [
        "attention_layer = BahdanauAttention(units)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qXp6Pil_w987"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, output_vocab_size, embedding_dim, dec_units):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.dec_units = dec_units\n",
        "    self.output_vocab_size = output_vocab_size\n",
        "    self.embedding_dim = embedding_dim\n",
        "\n",
        "    # For Step 1. The embedding layer convets token IDs to vectors\n",
        "    self.embedding = tf.keras.layers.Embedding(self.output_vocab_size,\n",
        "                                               embedding_dim)\n",
        "\n",
        "    # For Step 2. The RNN keeps track of what's been generated so far.\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "\n",
        "    # For step 3. The RNN output will be the query for the attention layer.\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "    # For step 4. Eqn. (3): converting `ct` to `at`\n",
        "    self.Wc = tf.keras.layers.Dense(dec_units, activation=tf.math.tanh,\n",
        "                                    use_bias=False)\n",
        "\n",
        "    # For step 5. This fully connected layer produces the logits for each\n",
        "    # output token.\n",
        "    self.fc = tf.keras.layers.Dense(self.output_vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ws1HvdD3w-A9"
      },
      "outputs": [],
      "source": [
        "class DecoderInput(typing.NamedTuple):\n",
        "  new_tokens: Any\n",
        "  enc_output: Any\n",
        "  mask: Any\n",
        "\n",
        "class DecoderOutput(typing.NamedTuple):\n",
        "  logits: Any\n",
        "  attention_weights: Any"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6eaXN0H-w-EY"
      },
      "outputs": [],
      "source": [
        "def call(self,\n",
        "         inputs: DecoderInput,\n",
        "         state=None) -> Tuple[DecoderOutput, tf.Tensor]:\n",
        "  shape_checker = ShapeChecker()\n",
        "  shape_checker(inputs.new_tokens, ('batch', 't'))\n",
        "  shape_checker(inputs.enc_output, ('batch', 's', 'enc_units'))\n",
        "  shape_checker(inputs.mask, ('batch', 's'))\n",
        "\n",
        "  if state is not None:\n",
        "    shape_checker(state, ('batch', 'dec_units'))\n",
        "\n",
        "  # Step 1. Lookup the embeddings\n",
        "  vectors = self.embedding(inputs.new_tokens)\n",
        "  shape_checker(vectors, ('batch', 't', 'embedding_dim'))\n",
        "\n",
        "  # Step 2. Process one step with the RNN\n",
        "  rnn_output, state = self.gru(vectors, initial_state=state)\n",
        "\n",
        "  shape_checker(rnn_output, ('batch', 't', 'dec_units'))\n",
        "  shape_checker(state, ('batch', 'dec_units'))\n",
        "\n",
        "  # Step 3. Use the RNN output as the query for the attention over the\n",
        "  # encoder output.\n",
        "  context_vector, attention_weights = self.attention(\n",
        "      query=rnn_output, value=inputs.enc_output, mask=inputs.mask)\n",
        "  shape_checker(context_vector, ('batch', 't', 'dec_units'))\n",
        "  shape_checker(attention_weights, ('batch', 't', 's'))\n",
        "\n",
        "  # Step 4. Eqn. (3): Join the context_vector and rnn_output\n",
        "  #     [ct; ht] shape: (batch t, value_units + query_units)\n",
        "  context_and_rnn_output = tf.concat([context_vector, rnn_output], axis=-1)\n",
        "\n",
        "  # Step 4. Eqn. (3): `at = tanh(Wc@[ct; ht])`\n",
        "  attention_vector = self.Wc(context_and_rnn_output)\n",
        "  shape_checker(attention_vector, ('batch', 't', 'dec_units'))\n",
        "\n",
        "  # Step 5. Generate logit predictions:\n",
        "  logits = self.fc(attention_vector)\n",
        "  shape_checker(logits, ('batch', 't', 'output_vocab_size'))\n",
        "\n",
        "  return DecoderOutput(logits, attention_weights), state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aW4D2A98xNKS"
      },
      "outputs": [],
      "source": [
        "Decoder.call = call"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8dseQLJxNNM"
      },
      "outputs": [],
      "source": [
        "'''le décodeur prend 4 paramètres :\n",
        "  new_tokens : le dernier jeton généré. Initialiser le décodeur avec le \"[START]\" jeton.\n",
        "  enc_output : il est généré par l'Encoder.\n",
        "  mask : tenseur booléen.\n",
        "  state : le précédent state de sortie du décodeur.\n",
        "'''\n",
        "decoder = Decoder(output_text_processor.vocabulary_size(),\n",
        "                  embedding_dim, units)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ln7c1jZ3xg5V"
      },
      "outputs": [],
      "source": [
        "#Fonction de perte\n",
        "class MaskedLoss(tf.keras.losses.Loss):\n",
        "  def __init__(self):\n",
        "    self.name = 'masked_loss'\n",
        "    self.loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True, reduction='none')\n",
        "\n",
        "  def __call__(self, y_true, y_pred):\n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(y_true, ('batch', 't'))\n",
        "    shape_checker(y_pred, ('batch', 't', 'logits'))\n",
        "\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    loss = self.loss(y_true, y_pred)\n",
        "    shape_checker(loss, ('batch', 't'))\n",
        "\n",
        "    # Mask off the losses on padding.\n",
        "    mask = tf.cast(y_true != 0, tf.float32)\n",
        "    shape_checker(mask, ('batch', 't'))\n",
        "    loss *= mask\n",
        "\n",
        "    # Return the total.\n",
        "    return tf.reduce_sum(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3Meqp95xg8O"
      },
      "outputs": [],
      "source": [
        "#Mettre en oeuvre l'étape de formation\n",
        "class TrainModel(tf.keras.Model):\n",
        "  def __init__(self, embedding_dim, units,\n",
        "               input_text_processor,\n",
        "               output_text_processor, \n",
        "               use_tf_function=True):\n",
        "    super().__init__()\n",
        "    # Build the encoder and decoder\n",
        "    encoder = Encoder(input_text_processor.vocabulary_size(),\n",
        "                      embedding_dim, units)\n",
        "    decoder = Decoder(output_text_processor.vocabulary_size(),\n",
        "                      embedding_dim, units)\n",
        "\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.input_text_processor = input_text_processor\n",
        "    self.output_text_processor = output_text_processor\n",
        "    self.use_tf_function = use_tf_function\n",
        "    self.shape_checker = ShapeChecker()\n",
        "\n",
        "  def train_step(self, inputs):\n",
        "    self.shape_checker = ShapeChecker()\n",
        "    if self.use_tf_function:\n",
        "      return self._tf_train_step(inputs)\n",
        "    else:\n",
        "      return self._train_step(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mmiaoD8lxg-k"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Cette fonction reçoit un lot de 'input_text', 'target_text' du tf.data.Dataset,\n",
        "puis convertit ces entrées de texte brut en incorporations de jetons et masques.\n",
        "'''\n",
        "def _preprocess(self, input_text, target_text):\n",
        "  self.shape_checker(input_text, ('batch',))\n",
        "  self.shape_checker(target_text, ('batch',))\n",
        "\n",
        "  # Convert the text to token IDs\n",
        "  input_tokens = self.input_text_processor(input_text)\n",
        "  target_tokens = self.output_text_processor(target_text)\n",
        "  self.shape_checker(input_tokens, ('batch', 's'))\n",
        "  self.shape_checker(target_tokens, ('batch', 't'))\n",
        "\n",
        "  # Convert IDs to masks.\n",
        "  input_mask = input_tokens != 0\n",
        "  self.shape_checker(input_mask, ('batch', 's'))\n",
        "\n",
        "  target_mask = target_tokens != 0\n",
        "  self.shape_checker(target_mask, ('batch', 't'))\n",
        "\n",
        "  return input_tokens, input_mask, target_tokens, target_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q52KM3oIxtmf"
      },
      "outputs": [],
      "source": [
        "TrainModel._preprocess = _preprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sAM1qsgLxtpH"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Cette fonction exécute l'encodeur sur les 'input_tokens' pour obtenir le 'encoder_output' \n",
        "et 'encoder_state', initialise l'état et la perte du décodeur, boucle sur les 'target_tokens' \n",
        "pour donner la perte moyenne, puis calcule le gradient de la perte et utilise l'optimiseur \n",
        "pour appliquer les mises à jour à du modèle 'trainable_variables' .\n",
        "'''\n",
        "def _train_step(self, inputs):\n",
        "  input_text, target_text = inputs  \n",
        "\n",
        "  (input_tokens, input_mask,\n",
        "   target_tokens, target_mask) = self._preprocess(input_text, target_text)\n",
        "\n",
        "  max_target_length = tf.shape(target_tokens)[1]\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    # Encode the input\n",
        "    enc_output, enc_state = self.encoder(input_tokens)\n",
        "    self.shape_checker(enc_output, ('batch', 's', 'enc_units'))\n",
        "    self.shape_checker(enc_state, ('batch', 'enc_units'))\n",
        "\n",
        "    # Initialize the decoder's state to the encoder's final state.\n",
        "    # This only works if the encoder and decoder have the same number of\n",
        "    # units.\n",
        "    dec_state = enc_state\n",
        "    loss = tf.constant(0.0)\n",
        "\n",
        "    for t in tf.range(max_target_length-1):\n",
        "      # Pass in two tokens from the target sequence:\n",
        "      # 1. The current input to the decoder.\n",
        "      # 2. The target for the decoder's next prediction.\n",
        "      new_tokens = target_tokens[:, t:t+2]\n",
        "      step_loss, dec_state = self._loop_step(new_tokens, input_mask,\n",
        "                                             enc_output, dec_state)\n",
        "      loss = loss + step_loss\n",
        "\n",
        "    # Average the loss over all non padding tokens.\n",
        "    average_loss = loss / tf.reduce_sum(tf.cast(target_mask, tf.float32))\n",
        "\n",
        "  # Apply an optimization step\n",
        "  variables = self.trainable_variables \n",
        "  gradients = tape.gradient(average_loss, variables)\n",
        "  self.optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  # Return a dict mapping metric names to current value\n",
        "  return {'batch_loss': average_loss}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xV4PSnUdxtuK"
      },
      "outputs": [],
      "source": [
        "TrainModel._train_step = _train_step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bi4veKcXxtw1"
      },
      "outputs": [],
      "source": [
        "def _loop_step(self, new_tokens, input_mask, enc_output, dec_state):\n",
        "  input_token, target_token = new_tokens[:, 0:1], new_tokens[:, 1:2]\n",
        "\n",
        "  # Run the decoder one step.\n",
        "  decoder_input = DecoderInput(new_tokens=input_token,\n",
        "                               enc_output=enc_output,\n",
        "                               mask=input_mask)\n",
        "\n",
        "  dec_result, dec_state = self.decoder(decoder_input, state=dec_state)\n",
        "  self.shape_checker(dec_result.logits, ('batch', 't1', 'logits'))\n",
        "  self.shape_checker(dec_result.attention_weights, ('batch', 't1', 's'))\n",
        "  self.shape_checker(dec_state, ('batch', 'dec_units'))\n",
        "\n",
        "  # `self.loss` returns the total for non-padded tokens\n",
        "  y = target_token\n",
        "  y_pred = dec_result.logits\n",
        "  step_loss = self.loss(y, y_pred)\n",
        "\n",
        "  return step_loss, dec_state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4iPfzhB-x63P"
      },
      "outputs": [],
      "source": [
        "TrainModel._loop_step = _loop_step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rhiLKQv3x66B"
      },
      "outputs": [],
      "source": [
        "model = TrainModel(\n",
        "    embedding_dim, units,\n",
        "    input_text_processor=input_text_processor,\n",
        "    output_text_processor=output_text_processor,\n",
        "    use_tf_function=False)\n",
        "\n",
        "# Configure the loss and optimizer\n",
        "model.compile(\n",
        "    optimizer=tf.optimizers.Adam(),\n",
        "    loss=MaskedLoss(),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBjS4yn1x68z",
        "outputId": "5402eb02-0d3d-463f-a074-ae0bab2bf5cd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8.517193191416238"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Tester l'étape de formation\n",
        "np.log(output_text_processor.vocabulary_size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bWN3NJOIyDju"
      },
      "outputs": [],
      "source": [
        "@tf.function(input_signature=[[tf.TensorSpec(dtype=tf.string, shape=[None]),\n",
        "                               tf.TensorSpec(dtype=tf.string, shape=[None])]])\n",
        "def _tf_train_step(self, inputs):\n",
        "  return self._train_step(inputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8sCUqZamyKQy"
      },
      "outputs": [],
      "source": [
        "TrainModel._tf_train_step = _tf_train_step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TmwLJAHmyR5M"
      },
      "outputs": [],
      "source": [
        "model.use_tf_function = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UqLh9_btyY3B"
      },
      "outputs": [],
      "source": [
        "#Entrainer le modèle\n",
        "train_model = TrainModel(\n",
        "    embedding_dim, units,\n",
        "    input_text_processor=input_text_processor,\n",
        "    output_text_processor=output_text_processor)\n",
        "\n",
        "# Configure the loss and optimizer\n",
        "train_model.compile(\n",
        "    optimizer=tf.optimizers.Adam(),\n",
        "    loss=MaskedLoss(),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SuFsxhtPyjWW"
      },
      "outputs": [],
      "source": [
        "class BatchLogs(tf.keras.callbacks.Callback):\n",
        "  def __init__(self, key):\n",
        "    self.key = key\n",
        "    self.logs = []\n",
        "\n",
        "  def on_train_batch_end(self, n, logs):\n",
        "    self.logs.append(logs[self.key])\n",
        "\n",
        "batch_loss = BatchLogs('batch_loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbhW420syjZ7",
        "outputId": "9f65f594-e724-44e6-9275-73c00f0a6cbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "2841/2841 [==============================] - 3684s 1s/step - batch_loss: 1.6416\n",
            "Epoch 2/3\n",
            "2841/2841 [==============================] - 3666s 1s/step - batch_loss: 0.8475\n",
            "Epoch 3/3\n",
            "2841/2841 [==============================] - 3674s 1s/step - batch_loss: 0.6855\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0f9d4efc10>"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_model.fit(dataset, epochs=3,\n",
        "                     callbacks=[batch_loss])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "U3m2r8JQyY8R",
        "outputId": "83c87ccd-c225-4615-9fc6-a5d7816173b5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'CE/token')"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(batch_loss.logs)\n",
        "plt.ylim([0, 3])\n",
        "plt.xlabel('Batch #')\n",
        "plt.ylabel('CE/token')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44ssn9cg-_WG"
      },
      "source": [
        "Remarque : les sauts visibles dans l'intrigue sont aux limites de l'époque."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "paGRthCzyq_C"
      },
      "outputs": [],
      "source": [
        "class Model(tf.Module):\n",
        "\n",
        "  def __init__(self, encoder, decoder, input_text_processor,\n",
        "               output_text_processor):\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.input_text_processor = input_text_processor\n",
        "    self.output_text_processor = output_text_processor\n",
        "\n",
        "    self.output_token_string_from_index = (\n",
        "        tf.keras.layers.StringLookup(\n",
        "            vocabulary=output_text_processor.get_vocabulary(),\n",
        "            mask_token='',\n",
        "            invert=True))\n",
        "\n",
        "    # The output should never generate padding, unknown, or start.\n",
        "    index_from_string = tf.keras.layers.StringLookup(\n",
        "        vocabulary=output_text_processor.get_vocabulary(), mask_token='')\n",
        "    token_mask_ids = index_from_string(['', '[UNK]', '[START]']).numpy()\n",
        "\n",
        "    token_mask = np.zeros([index_from_string.vocabulary_size()], dtype=np.bool)\n",
        "    token_mask[np.array(token_mask_ids)] = True\n",
        "    self.token_mask = token_mask\n",
        "\n",
        "    self.start_token = index_from_string(tf.constant('[START]'))\n",
        "    self.end_token = index_from_string(tf.constant('[END]'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTUgbWyLyrB0"
      },
      "outputs": [],
      "source": [
        "model = Model(\n",
        "    encoder=train_model.encoder,\n",
        "    decoder=train_model.decoder,\n",
        "    input_text_processor=input_text_processor,\n",
        "    output_text_processor=output_text_processor,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yIMDmBjwyY_t"
      },
      "outputs": [],
      "source": [
        "#Convertir les identifiants de jeton en texte.\n",
        "def tokens_to_text(self, result_tokens):\n",
        "  shape_checker = ShapeChecker()\n",
        "  shape_checker(result_tokens, ('batch', 't'))\n",
        "  result_text_tokens = self.output_token_string_from_index(result_tokens)\n",
        "  shape_checker(result_text_tokens, ('batch', 't'))\n",
        "\n",
        "  result_text = tf.strings.reduce_join(result_text_tokens,\n",
        "                                       axis=1, separator=' ')\n",
        "  shape_checker(result_text, ('batch'))\n",
        "\n",
        "  result_text = tf.strings.strip(result_text)\n",
        "  shape_checker(result_text, ('batch',))\n",
        "  return result_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4Uw3uC4yx_9"
      },
      "outputs": [],
      "source": [
        "Model.tokens_to_text = tokens_to_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DxpQfraiyyIO"
      },
      "outputs": [],
      "source": [
        "def sample(self, logits, temperature):\n",
        "  shape_checker = ShapeChecker()\n",
        "  # 't' is usually 1 here.\n",
        "  shape_checker(logits, ('batch', 't', 'vocab'))\n",
        "  shape_checker(self.token_mask, ('vocab',))\n",
        "\n",
        "  token_mask = self.token_mask[tf.newaxis, tf.newaxis, :]\n",
        "  shape_checker(token_mask, ('batch', 't', 'vocab'), broadcast=True)\n",
        "\n",
        "  # Set the logits for all masked tokens to -inf, so they are never chosen.\n",
        "  logits = tf.where(self.token_mask, -np.inf, logits)\n",
        "\n",
        "  if temperature == 0.0:\n",
        "    new_tokens = tf.argmax(logits, axis=-1)\n",
        "  else: \n",
        "    logits = tf.squeeze(logits, axis=1)\n",
        "    new_tokens = tf.random.categorical(logits/temperature,\n",
        "                                        num_samples=1)\n",
        "\n",
        "  shape_checker(new_tokens, ('batch', 't'))\n",
        "\n",
        "  return new_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvODBEEEyyK1"
      },
      "outputs": [],
      "source": [
        "Model.sample = sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKey90R5zC6N"
      },
      "outputs": [],
      "source": [
        "def model_unrolled(self,\n",
        "                       input_text, *,\n",
        "                       max_length=50,\n",
        "                       return_attention=True,\n",
        "                       temperature=1.0):\n",
        "  batch_size = tf.shape(input_text)[0]\n",
        "  input_tokens = self.input_text_processor(input_text)\n",
        "  enc_output, enc_state = self.encoder(input_tokens)\n",
        "\n",
        "  dec_state = enc_state\n",
        "  new_tokens = tf.fill([batch_size, 1], self.start_token)\n",
        "\n",
        "  result_tokens = []\n",
        "  attention = []\n",
        "  done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
        "\n",
        "  for _ in range(max_length):\n",
        "    dec_input = DecoderInput(new_tokens=new_tokens,\n",
        "                             enc_output=enc_output,\n",
        "                             mask=(input_tokens!=0))\n",
        "\n",
        "    dec_result, dec_state = self.decoder(dec_input, state=dec_state)\n",
        "\n",
        "    attention.append(dec_result.attention_weights)\n",
        "\n",
        "    new_tokens = self.sample(dec_result.logits, temperature)\n",
        "\n",
        "    # If a sequence produces an `end_token`, set it `done`\n",
        "    done = done | (new_tokens == self.end_token)\n",
        "    # Once a sequence is done it only produces 0-padding.\n",
        "    new_tokens = tf.where(done, tf.constant(0, dtype=tf.int64), new_tokens)\n",
        "\n",
        "    # Collect the generated tokens\n",
        "    result_tokens.append(new_tokens)\n",
        "\n",
        "    if tf.executing_eagerly() and tf.reduce_all(done):\n",
        "      break\n",
        "\n",
        "  # Convert the list of generates token ids to a list of strings.\n",
        "  result_tokens = tf.concat(result_tokens, axis=-1)\n",
        "  result_text = self.tokens_to_text(result_tokens)\n",
        "\n",
        "  if return_attention:\n",
        "    attention_stack = tf.concat(attention, axis=1)\n",
        "    return {'text': result_text, 'attention': attention_stack}\n",
        "  else:\n",
        "    return {'text': result_text}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qKld1YLzC-8"
      },
      "outputs": [],
      "source": [
        "Model.translate = model_unrolled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4hXho18zDBm",
        "outputId": "50a74462-2464-4e2f-9c4f-e362f6c2acb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "a698\n",
            "i802\n",
            "\n",
            "CPU times: user 197 ms, sys: 3.05 ms, total: 200 ms\n",
            "Wall time: 187 ms\n"
          ]
        }
      ],
      "source": [
        "#Exécution sur une simple entrée \n",
        "%%time\n",
        "input_text = tf.constant([\n",
        "    'Gangrène due à spirochètes NCA.', # \"A698\"\n",
        "    'Thrombose veineuse profonde cuisse gauche', # \"I802\"\"\n",
        "])\n",
        "\n",
        "result = model.translate(\n",
        "    input_text = input_text)\n",
        "\n",
        "print(result['text'][0].numpy().decode())\n",
        "print(result['text'][1].numpy().decode())\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hnpQEcjBzDGc"
      },
      "outputs": [],
      "source": [
        "@tf.function(input_signature=[tf.TensorSpec(dtype=tf.string, shape=[None])])\n",
        "def tf_model(self, input_text):\n",
        "  return self.model(input_text)\n",
        "\n",
        "Model.tf_model = tf_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfuKKJ3_zZFd"
      },
      "outputs": [],
      "source": [
        "@tf.function(input_signature=[tf.TensorSpec(dtype=tf.string, shape=[None])])\n",
        "def tf_model(self, input_text):\n",
        "  return self.translate(input_text)\n",
        "\n",
        "Model.tf_model = tf_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YuEeNbjPzZI_",
        "outputId": "fd9b4a04-6b89-4596-b3f6-b3565201da6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 27.2 s, sys: 703 ms, total: 27.9 s\n",
            "Wall time: 27.4 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "result = model.tf_model(\n",
        "    input_text = input_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWSYiW-TzZWB",
        "outputId": "2ced1d8e-f644-4878-d6f5-229c44ae38f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "z952\n",
            "g819\n",
            "c07\n",
            "\n",
            "CPU times: user 917 ms, sys: 28.2 ms, total: 945 ms\n",
            "Wall time: 583 ms\n"
          ]
        }
      ],
      "source": [
        "#Un autr test\n",
        "%%time\n",
        "three_input_text = tf.constant([\n",
        "    # I38.\n",
        "    'Prothèse valvulaire mécanique.',\n",
        "    # 489F\n",
        "    'Névropathie',\n",
        "    # C07'\n",
        "    'Tumeur mixte parotide dégénérée',\n",
        "])\n",
        "\n",
        "result = model.tf_model(three_input_text)\n",
        "\n",
        "for tr in result['text']:\n",
        "  print(tr.numpy().decode())\n",
        "\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2jfDRA5zZWy",
        "outputId": "d87af283-511f-43e9-f8d3-0319a4afa05a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'z952', b'g819', b'c07'], dtype=object)>"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result['text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhOv6mJJzZXm",
        "outputId": "bf2eaf0a-c5a1-4e7b-b18a-20acd36824b8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as encoder_1_layer_call_fn, encoder_1_layer_call_and_return_conditional_losses, decoder_2_layer_call_fn, decoder_2_layer_call_and_return_conditional_losses, embedding_3_layer_call_fn while saving (showing 5 of 60). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model/assets\n"
          ]
        }
      ],
      "source": [
        "tf.saved_model.save(model, 'model',\n",
        "                    signatures={'serving_default': model.tf_model})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jMViDS0hzO51"
      },
      "outputs": [],
      "source": [
        "reloaded = tf.saved_model.load('model')\n",
        "#result = reloaded.tf_model(three_input_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VB6QNgwRmhQr",
        "outputId": "4af82506-d0f9-4271-faa8-841ca0e895ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "z952\n",
            "x44\n",
            "c07\n",
            "\n",
            "CPU times: user 929 ms, sys: 30.2 ms, total: 959 ms\n",
            "Wall time: 590 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "result = reloaded.tf_model(three_input_text)\n",
        "for tr in result['text']:\n",
        "  print(tr.numpy().decode())\n",
        "\n",
        "print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzj_9vtimhTt",
        "outputId": "ca3c4051-734d-4662-e064-4453649eb010"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "y19\n",
            "a183\n",
            "z904\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Un autre test\n",
        "\n",
        "three_input_text = tf.constant([\n",
        "    # Y19.\n",
        "    'Toxique',\n",
        "    # A183\n",
        "    'Péritonite tuberculeuse',\n",
        "    # 489F'\n",
        "    'Névropathie',\n",
        "])\n",
        "\n",
        "result = reloaded.tf_model(three_input_text)\n",
        "\n",
        "for tr in result['text']:\n",
        "  print(tr.numpy().decode())\n",
        "\n",
        "print()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "847GP8BjW6Ec",
        "Y6UbcRqtW9wi",
        "iOHcd0rdYNGf",
        "dM-VlZi8XD4T",
        "tW1HKWFsW9y-",
        "p1OsK4jVeNzl",
        "iIVEvRUrW7tz",
        "UvEgdmxpZ_r2",
        "X5T8ptq-vBdz",
        "PwzjgW4qm5pL",
        "ix3bxM56rhtv",
        "1az_L2_qTteF",
        "55GL5uKQT6pJ",
        "GSUdeDjXGyE-",
        "3SXT-lZJMPdf",
        "ud44BvZWElJP",
        "KzBCq_7epCWd",
        "Vu_JgJgm6Hzg",
        "plOx4hJpHHJw",
        "1M9FaHf6G5Hn",
        "ig-U_14tDXF5",
        "KHGF1W7mGV4o",
        "ihwYOlzIpEoe",
        "WchGbtrSwDaq",
        "kTExj2Q6Vkjc",
        "N15AD6-0FLPm"
      ],
      "name": "projet.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
